# Sources

This project has utilized a variety of tools, libraries, APIs, and knowledge bases. Below is a comprehensive list of sources that were instrumental in its development:

## Libraries and APIs
- **OpenAI GPT-4**: For natural language understanding and generation.
- **Whisper-1**: Advanced speech-to-text processing.
- **Google Gemini API**: Multimodal AI capabilities.
- **ASUS Aura Sync SDK**: RGB lighting control for compatible devices.
- **Razer Chroma SDK**: Dynamic RGB lighting effects integration.
- **MediaPipe**: Gesture recognition and real-time video processing.
- **Flask**: Backend web framework.
- **Discord.py**: Discord bot framework for chat integration.
- **Pillow**: Python Imaging Library for image processing.
- **TextBlob**: Sentiment analysis and text processing.
- **Tesseract OCR**: Optical Character Recognition for image-to-text conversion.

## Open-Source Contributions
- Libraries and tools from the Python community on PyPI.
- Open documentation and guides provided by GitHub repositories and community forums.

## Academic and Research Papers
- Papers and articles on sentiment analysis and multimodal AI for refining emotional and gesture recognition systems.

## Tutorials and Guides
- Official documentation for the above libraries and SDKs.
- Video tutorials and blog posts from trusted development and AI platforms.

---

The combined efforts of these sources and the innovation of their developers have greatly contributed to the success of this project. We extend our deepest gratitude for their work and the resources they have made available.

